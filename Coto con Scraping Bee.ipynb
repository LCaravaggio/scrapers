{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfgNUqwhSV3/3BDZerNKDC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LCaravaggio/scrapers/blob/master/Coto%20con%20Scraping%20Bee.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2xS3ioRUzHa"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrapcoto(l):\n",
        "  try:\n",
        "    response = requests.get(\n",
        "        url='https://app.scrapingbee.com/api/v1/',\n",
        "        params={\n",
        "            'api_key': '', # AC√Å PONER LA KEY\n",
        "            'url': l,\n",
        "            'premium_proxy': 'false',\n",
        "            'stealth_proxy': 'false',\n",
        "            'country_code':'ar'\n",
        "        },\n",
        "\n",
        "    )\n",
        "    b=\"\"\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    b+=soup.find(\"h1\", {\"class\": \"product_page\"}).text.replace(\" \",\"\").replace(\"\\n\",\"\").replace(\"\\r\",\"\").replace(\";\",\"\").replace(\"\\t\",\"\") + \";\"\n",
        "    try:\n",
        "        b+=soup.find(\"span\", {\"class\": \"atg_store_newPrice\"}).text.replace(\"$\",\"\").replace(\" \",\"\").replace(\"\\n\",\"\").replace(\"\\r\",\"\").replace(\"\\t\",\"\").replace(\"PRECIOCONTADO\",\"\").replace(\"PRECIOREGULAR\",\"\")\n",
        "    except:\n",
        "        b+=soup.find(\"span\", {\"class\": \"price_regular_precio\"}).text.replace(\"$\",\"\").replace(\" \",\"\").replace(\"\\n\",\"\").replace(\"\\r\",\"\").replace(\"\\t\",\"\").replace(\"PRECIOCONTADO\",\"\").replace(\"PRECIOREGULAR\",\"\")\n",
        "  except Exception as e:\n",
        "      return \"no se pudo acceder a COTO\"\n",
        "  return b"
      ],
      "metadata": {
        "id": "wNISI2cTU1yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def corre(lista, nombre):\n",
        "  a=\"\"\n",
        "\n",
        "  for l in lista:\n",
        "    a+= l + \";\"\n",
        "    a+=scrapcoto(l)\n",
        "    a+=\"\\n\"\n",
        "    site=l\n",
        "\n",
        "  now = datetime.datetime.now()\n",
        "  nw=str(now.strftime(\"%Y-%m-%d %H-%M-%S\"))\n",
        "\n",
        "  with open('/content/' + str(nombre) + ' ' + nw + '.csv', 'w', newline=\"\\n\", encoding='utf-8') as f:\n",
        "    f.write(a.replace('\\u2022', '*'))\n",
        "    f.close"
      ],
      "metadata": {
        "id": "xzp1SeD7U3G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/supermercados.txt') as file:\n",
        "    lista = [line.rstrip() for line in file]\n",
        "    corre(lista, 'supermercados')"
      ],
      "metadata": {
        "id": "-hv0poz7U4Wc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}